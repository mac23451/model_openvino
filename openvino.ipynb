{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12N7rzmYTPK2XIpRBeyuOxj0dgkteKmT_","timestamp":1711883535611}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F08nThBhQz-n","executionInfo":{"status":"ok","timestamp":1711894668486,"user_tz":-480,"elapsed":25532,"user":{"displayName":"mac樹","userId":"10867368172307707005"}},"outputId":"0816004b-8548-42fd-ae60-80a8d669319b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openvino\n","  Downloading openvino-2024.0.0-14509-cp310-cp310-manylinux2014_x86_64.whl (38.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from openvino) (1.25.2)\n","Collecting openvino-telemetry>=2023.2.1 (from openvino)\n","  Downloading openvino_telemetry-2023.2.1-py3-none-any.whl (23 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openvino) (24.0)\n","Installing collected packages: openvino-telemetry, openvino\n","Successfully installed openvino-2024.0.0 openvino-telemetry-2023.2.1\n","Collecting onnx\n","  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.16.0\n"]}],"source":["!pip install openvino\n","!pip install onnx\n","# the torch require onnx"]},{"cell_type":"code","source":["import datetime\n","import time\n"],"metadata":{"id":"-IaIRYaRcHFZ","executionInfo":{"status":"ok","timestamp":1711894668486,"user_tz":-480,"elapsed":4,"user":{"displayName":"mac樹","userId":"10867368172307707005"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch import nn, optim\n","from openvino.runtime import Core\n","\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n","        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n","        self.fc1 = nn.Linear(4*4*50, 500)\n","        self.fc2 = nn.Linear(500, 10)\n","\n","    def forward(self, x):\n","        x = nn.functional.relu(self.conv1(x))\n","        x = nn.functional.max_pool2d(x, 2, 2)\n","        x = nn.functional.relu(self.conv2(x))\n","        x = nn.functional.max_pool2d(x, 2, 2)\n","        x = x.view(-1, 4*4*50)\n","        x = nn.functional.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","model = SimpleCNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Original model training\n","for epoch in range(10):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n","\n","print('Finished Training')\n","\n","\n","# Original model testing\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n","\n","\n","def test_model(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","\n","accuracy = test_model(model, testloader)\n","print(f'Accuracy of the model on the 10000 test images: {accuracy} %')\n","\n","\n","\n","\n","\n","###### The following is openvino part\n","\n","\n","dummy_input = torch.randn(1, 1, 28, 28)\n","\n","\n","\n","torch.onnx.export(model, dummy_input, \"simple_model.onnx\", export_params=True,\n","                          opset_version=11, do_constant_folding=True,\n","                          input_names=['input'], output_names=['output'],\n","                          dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n","print(\"Model has been converted to ONNX format and saved as simple_model.onnx\")\n","\n","\n","\n","\n","ie = Core()\n","\n","model_path = \"simple_model.onnx\"\n","ovmodel = ie.read_model(model=model_path)\n","\n","# Compile the model for a specific device\n","compiled_ovmodel = ie.compile_model(model=ovmodel, device_name=\"CPU\")\n","\n","\n","input_layer = compiled_ovmodel.input(0)\n","output_layer = compiled_ovmodel.output(0)\n","\n","correct = 0\n","total = 0\n","\n","# Open vino test\n","for images, labels in testloader:\n","    images = images.numpy()\n","\n","    for i in range(images.shape[0]):\n","        image = images[i]\n","        image = image.reshape((1, 1, 28, 28))\n","        results = compiled_ovmodel([image])[output_layer]\n","\n","        pred = np.argmax(results, axis=1)\n","        correct += (pred == labels[i].numpy()).sum().item()\n","        total += labels.size(0)\n","\n","\n","print(f'Accuracy on the MNIST test set: {accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xW_MxOBWQ2zs","executionInfo":{"status":"ok","timestamp":1711895183349,"user_tz":-480,"elapsed":514866,"user":{"displayName":"mac樹","userId":"10867368172307707005"}},"outputId":"3f25a50b-f84d-4d84-aaad-1911dbef6b45"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 113712902.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 99782284.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 32861303.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 19479068.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.8300585974571801\n","Epoch 2, Loss: 0.1644498827174179\n","Epoch 3, Loss: 0.1075042290047113\n","Epoch 4, Loss: 0.08441964117214401\n","Epoch 5, Loss: 0.07054655564907215\n","Epoch 6, Loss: 0.06140543161325458\n","Epoch 7, Loss: 0.05459723339008012\n","Epoch 8, Loss: 0.048943941540736106\n","Epoch 9, Loss: 0.044910253075980094\n","Epoch 10, Loss: 0.04206318167948734\n","Finished Training\n","Accuracy of the model on the 10000 test images: 98.77 %\n","Model has been converted to ONNX format and saved as simple_model.onnx\n","Accuracy on the MNIST test set: 98.7700\n"]}]},{"cell_type":"code","source":["# The follwing is evaluation of time of openvino comparing with original model.\n","# The timer only calculate the exact time of model runing time for testdata (other like compiling and calculating performance won't be included)\n","# note that the torch model expect to run the testdata with batch datasets. In this evaluation, torch model only take input 1 data for each loop.\n","\n","\n","\n","\n","\n","ie = Core()\n","\n","\n","model_path = \"simple_model.onnx\"\n","ovmodel = ie.read_model(model=model_path)\n","\n","\n","compiled_ovmodel = ie.compile_model(model=ovmodel, device_name=\"CPU\")\n","\n","\n","input_layer = compiled_ovmodel.input(0)\n","output_layer = compiled_ovmodel.output(0)\n","\n","correct = 0\n","correcto = 0\n","t_c=0\n","to_c=0\n","\n","total = 0\n","for images, labels in testloader:\n","    images = images.numpy()\n","\n","    for i in range(images.shape[0]):\n","\n","        image = images[i]\n","        image = image.reshape((1, 1, 28, 28))\n","\n","        to_a=time.time()\n","        results = compiled_ovmodel([image])[output_layer]\n","        to_b=time.time()\n","        to_c=to_c+to_b-to_a\n","\n","        t_a=time.time()\n","        outputs = model(torch.from_numpy(image))\n","        t_b=time.time()\n","        t_c=t_c+t_b-t_a\n","\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        correcto += (predicted == labels[i]).sum().item()\n","\n","\n","        pred = np.argmax(results, axis=1)\n","        correct += (pred == labels[i].numpy()).item()\n","    total += labels.size(0)\n","\n","\n","print(\"ori_model accuracy:\",correcto/total)\n","print(\"openvino_model accuracy:\",correct/total)\n","print(\"ori_model:\",t_c,\"openvino_model:\",to_c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JR08fPheb2Z6","executionInfo":{"status":"ok","timestamp":1711895203548,"user_tz":-480,"elapsed":20204,"user":{"displayName":"mac樹","userId":"10867368172307707005"}},"outputId":"2a4c680b-3e8b-4e2d-e7b8-c64429c35a6c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ori_model accuracy: 0.9877\n","openvino_model accuracy: 0.9877\n","ori_model: 10.502442836761475 openvino_model: 5.389642953872681\n"]}]},{"cell_type":"code","source":["# the following is the evaluation of total time for runing the whole testdata with openvino(including calculating performance)\n","\n","\n","model_path = \"simple_model.onnx\"\n","ovmodel = ie.read_model(model=model_path)\n","\n","\n","compiled_model = ie.compile_model(model=ovmodel, device_name=\"CPU\")\n","\n","\n","input_layer = compiled_model.input(0)\n","output_layer = compiled_model.output(0)\n","\n","correct = 0\n","correcto = 0\n","\n","total = 0\n","\n","\n","a = time.time()\n","for images, labels in testloader:\n","    images = images.numpy()\n","\n","    for i in range(images.shape[0]):\n","\n","        image = images[i]\n","        image = image.reshape((1, 1, 28, 28))\n","        results = compiled_model([image])[output_layer]\n","\n","\n","        pred = np.argmax(results, axis=1)\n","        correct += (pred == labels[i].numpy()).item()\n","    total += labels.size(0)\n","\n","b = time.time()\n","\n","print(correct/total)\n","print(\"time: \",b-a)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aa8EXReyqlsa","executionInfo":{"status":"ok","timestamp":1711895209263,"user_tz":-480,"elapsed":5729,"user":{"displayName":"mac樹","userId":"10867368172307707005"}},"outputId":"33d34f16-c38d-4014-ffcc-ce9738c9b6eb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9877\n","time:  5.713577747344971\n"]}]},{"cell_type":"code","source":["# the following is the evaluation of total time for runing the whole testdata with original model(including calculating performance)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n","\n","\n","def test_model(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","\n","a = time.time()\n","accuracy = test_model(model, testloader)\n","b = time.time()\n","print(f'Accuracy of the model on the 10000 test images: {accuracy} %')\n","print(\"time: \",b-a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S4E8V1TJdwKd","executionInfo":{"status":"ok","timestamp":1711895213862,"user_tz":-480,"elapsed":4615,"user":{"displayName":"mac樹","userId":"10867368172307707005"}},"outputId":"69205aae-7c1f-4e35-9000-03916214b042"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the model on the 10000 test images: 98.77 %\n","time:  4.585016489028931\n"]}]},{"cell_type":"code","source":["# the following is the evaluation of total time for runing the whole testdata with original model(including calculating performance)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n","\n","def test_model(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    k_c=0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","\n","            k_a=time.time()\n","            outputs = model(images)\n","            k_b=time.time()\n","            k_c=k_c+k_b-k_a\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(\"ptime: \",k_c)\n","    return accuracy\n","\n","a = time.time()\n","accuracy = test_model(model, testloader)\n","b = time.time()\n","print(f'Accuracy of the model on the 10000 test images: {accuracy} %')\n","print(\"time: \",b-a)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zL9VDspkvDjo","executionInfo":{"status":"ok","timestamp":1711895217908,"user_tz":-480,"elapsed":4062,"user":{"displayName":"mac樹","userId":"10867368172307707005"}},"outputId":"9808b42e-5311-4f68-9211-71852c314ca7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["ptime:  2.002572536468506\n","Accuracy of the model on the 10000 test images: 98.77 %\n","time:  3.9503231048583984\n"]}]}]}
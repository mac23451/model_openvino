{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F08nThBhQz-n",
        "outputId": "1ce3f53c-7c93-4145-b731-9fbea74afacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openvino\n",
            "  Downloading openvino-2024.0.0-14509-cp310-cp310-manylinux2014_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from openvino) (1.25.2)\n",
            "Collecting openvino-telemetry>=2023.2.1 (from openvino)\n",
            "  Downloading openvino_telemetry-2023.2.1-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openvino) (24.0)\n",
            "Installing collected packages: openvino-telemetry, openvino\n",
            "Successfully installed openvino-2024.0.0 openvino-telemetry-2023.2.1\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openvino\n",
        "!pip install onnx\n",
        "# the torch require onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-IaIRYaRcHFZ"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW_MxOBWQ2zs",
        "outputId": "4bc25226-8117-4609-82a1-327d5b50af3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.45273880164490454\n",
            "Finished Training\n",
            "Accuracy of the model on the 10000 test images: 98.41 %\n",
            "Model has been converted to ONNX format and saved as simple_model.onnx\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "from openvino.runtime import Core\n",
        "\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Convolutional Block 1\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Convolutional Block 2\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Convolutional Block 3\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 1024)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(512, 10)  # Output layer: 10 classes for MNIST\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional Block 1\n",
        "        x = self.pool1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
        "        # Convolutional Block 2\n",
        "        x = self.pool2(F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x)))))))\n",
        "        # Convolutional Block 3\n",
        "        x = self.pool3(F.relu(self.bn6(self.conv6(F.relu(self.bn5(self.conv5(x)))))))\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        # Fully connected layers with dropout in between\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Original model training\n",
        "for epoch in range(1):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "# Original model testing\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "def test_model(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "accuracy = test_model(model, testloader)\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy} %')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in_geM3B8mBH",
        "outputId": "fac60264-3b9a-402f-9768-d4d462a356ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has been converted to ONNX format and saved as simple_model.onnx\n",
            "compile time: 0.025894880294799805\n"
          ]
        }
      ],
      "source": [
        "###### The following is openvino part\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(64, 1, 28, 28)\n",
        "\n",
        "\n",
        "\n",
        "torch.onnx.export(model, dummy_input, \"complex_gpu_model.onnx\", export_params=True,\n",
        "                          opset_version=11, do_constant_folding=True,\n",
        "                          input_names=['input'], output_names=['output'],\n",
        "                          dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
        "print(\"Model has been converted to ONNX format and saved as simple_model.onnx\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ie = Core()\n",
        "\n",
        "model_path = \"simple_model.onnx\"\n",
        "ovmodel = ie.read_model(model=model_path)\n",
        "\n",
        "# Compile the model for a specific device\n",
        "cuta = time.time()\n",
        "compiled_ovmodel = ie.compile_model(model=ovmodel, device_name=\"CPU\")\n",
        "cutb = time.time()\n",
        "print(\"compile time:\",cutb-cuta)\n",
        "#input_layer = compiled_ovmodel.input(0)\n",
        "#output_layer = compiled_ovmodel.output(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGbuanc67QHA",
        "outputId": "0eb1d11e-9e81-4409-d45e-59b9cf2f1568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 98.41 %\n",
            "exact time for original model:  14.936014175415039\n",
            "Accuracy of the vinomodel on the 10000 test images: 98.41 %\n",
            "exact time for vino model:  11.024291515350342\n",
            "Accuracy of the model on the 10000 test images: 98.41 %\n",
            "exact time for original model:  16.69730544090271\n",
            "Accuracy of the vinomodel on the 10000 test images: 98.41 %\n",
            "exact time for vino model:  10.255162715911865\n",
            "Accuracy of the model on the 10000 test images: 98.41 %\n",
            "exact time for original model:  15.086392164230347\n",
            "Accuracy of the vinomodel on the 10000 test images: 98.41 %\n",
            "exact time for vino model:  10.273751258850098\n",
            "Accuracy of the model on the 10000 test images: 98.41 %\n",
            "exact time for original model:  14.833641290664673\n",
            "Accuracy of the vinomodel on the 10000 test images: 98.41 %\n",
            "exact time for vino model:  10.300639152526855\n",
            "Accuracy of the model on the 10000 test images: 98.41 %\n",
            "exact time for original model:  14.824760437011719\n",
            "Accuracy of the vinomodel on the 10000 test images: 98.41 %\n",
            "exact time for vino model:  10.295271396636963\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    ori_t_s=0\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        ori_t_a=time.time()\n",
        "        outputs = model(images)\n",
        "        ori_t_b=time.time()\n",
        "        ori_t_s= ori_t_s + ori_t_b - ori_t_a\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model on the 10000 test images: {accuracy} %')\n",
        "    print(\"exact time for original model: \",ori_t_s)\n",
        "\n",
        "\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    vino_t_s=0\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        vino_t_a=time.time()\n",
        "        outputs = compiled_ovmodel(images)[compiled_ovmodel.output(0)]\n",
        "        vino_t_b=time.time()\n",
        "        vino_t_s= vino_t_s + vino_t_b - vino_t_a\n",
        "        outputs = torch.from_numpy(outputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the vinomodel on the 10000 test images: {accuracy} %')\n",
        "    print(\"exact time for vino model: \",vino_t_s)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}